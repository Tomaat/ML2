{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Bayesian PCA\n",
    "\n",
    "### Machine Learning II, 2016\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The lab exercises should be made in groups of two people.\n",
    "* The deadline for part 1 is Sunday, 15 May, 23:59.\n",
    "* Assignment should be sent to taco.cohen at gmail dot com. The subject line of your email should be \"[MLII2016] lab3part1_lastname1\\_lastname2\". \n",
    "* Put your and your teammates' names in the body of the email\n",
    "* Attach the .IPYNB (IPython Notebook) file containing your code and answers. Naming of the file follows the same rule as the subject line. For example, if the subject line is \"[MLII2016] lab01\\_Kingma\\_Hu\", the attached file should be \"lab3part1\\_Kingma\\_Hu.ipynb\". Only use underscores (\"\\_\") to connect names, otherwise the files cannot be parsed.\n",
    "\n",
    "Notes on implementation:\n",
    "\n",
    "* You should write your code and answers in an IPython Notebook: http://ipython.org/notebook.html. If you have problems, please contact us.\n",
    "* Among the first lines of your notebook should be \"%pylab inline\". This imports all required modules, and your plots will appear inline.\n",
    "* NOTE: test your code and make sure we can run your notebook / scripts!\n",
    "* NOTE: please write your answers directly below the question in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\vline}{\\mid}$\n",
    "$\\newcommand{\\hline}{\\dfrac{\\quad}{}}$\n",
    "$\\newcommand{\\mwtilde}[1][i]{\\tilde{\\vt{m}}_{\\vt{w}}^{(#1)}}$\n",
    "$\\newcommand{\\mw}[1][k]{{\\vt{m}_{\\vt{w}}^{(#1)}}}$\n",
    "$%\\newcommand{\\E}[1]{\\mathbb{E}\\left[ #1 \\right]}$\n",
    "$\\newcommand{\\E}[1]{\\left \\langle #1 \\right\\rangle}$\n",
    "$\\newcommand{\\EE}[1]{\\left\\langle #1 \\right\\rangle}$\n",
    "$\\newcommand{\\vt}[1]{\\boldsymbol{\\mathbf{#1}}}$\n",
    "$\\newcommand{\\gaus}[1]{\\mathcal{N}\\left(#1\\right)}$\n",
    "$\\newcommand{\\lb}[0]{\\left [}$\n",
    "$\\newcommand{\\rb}[0]{\\right ]}$\n",
    "$\\newcommand{\\lp}{\\left(}$\n",
    "$\\newcommand{\\rp}{\\right)}$\n",
    "$\\newcommand{\\la}{\\left \\{}$\n",
    "$\\newcommand{\\ra}{\\right \\}}$\n",
    "\n",
    "> #### By: Ysbrand Galama, 10262067\n",
    "> #### Ties van Rozendaal, 10077391"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this lab assignment, we will implement a variational algorithm for Bayesian PCA. Unlike regular PCA based on maximization of retained variance or minimization of projection error (see Bishop, 12.1.1 and 12.1.2), probabilistic PCA defines a proper density model over observed and latent variables. We will work with a fully Bayesian model this time, which is to say that we will put priors on our parameters and will be interested in learning the posterior over those parameters. Bayesian methods are very elegant, but require a shift in mindset: we are no longer looking for a point estimate of the parameters (as in maximum likelihood or MAP), but for a full posterior distribution over the space of parameters.\n",
    "\n",
    "The integrals involved in a Bayesian analysis are usually analytically intractable, so that we must resort to approximations. In this lab assignment, we will implement the variational method described in Bishop99. Chapters 10 and 12 of the PRML book contain additional material that may be useful when doing this exercise.\n",
    "\n",
    "* [Bishop99] Variational Principal Components, C. Bishop, ICANN 1999 - http://research.microsoft.com/pubs/67241/bishop-vpca-icann-99.pdf\n",
    "\n",
    "Below, you will find some code to get you started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The Q-distribution (5 points)\n",
    "\n",
    "In variational Bayes, we introduce a distribution $Q(\\Theta)$ over parameters / latent variables in order to make inference tractable. We can think of $Q$ as being an approximation of a certain distribution. What function does $Q$ approximate, $p(D|\\Theta)$, $p(\\Theta|D)$, $p(D, \\Theta)$, $p(\\Theta)$, or $p(D)$, and how do you see that from the equation $\\ln p(D) = \\mathcal{L}(Q) + \\mathrm{KL}(Q||P)$? (Hint: see eq. 11 in Bishop99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The function $Q$ approximates $p(\\Theta|D)$, which is what we want, to make the $KL$ as small as possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The mean-field approximation (15 points)\n",
    "\n",
    "Equation 13 from [Bishop99] is a very powerful result: assuming only that $Q(\\Theta)$ factorizes in a certain way (no assumptions on the functional form of the factors $Q_i$!), we get a set of coupled equations for the $Q_i$.\n",
    "\n",
    "However, the expression given in eq. 13 for Q_i contains a small mistake. Starting with the expression for the lower bound $\\mathcal{L}(Q)$, derive the correct expression (and include your derivation). You can proceed as follows: first, substitute the factorization of $Q$ (eq. 12) into the definition of $\\mathcal{L}(Q)$ and separate $\\mathcal{L}(Q)$ into $Q_i$-dependent and $Q_i$-independent terms. At this point, you should be able to spot the expectations $\\langle\\cdot\\rangle_{k \\neq i}$ over the other $Q$-distributions that appear in Bishop's solution (eq. 13). Now, keeping all $Q_k, k \\neq i$ fixed, maximize the expression with respect to $Q_i$. You should be able to spot the form of the optimal $\\ln Q_i$, from which $Q_i$ can easily be obtained.\n",
    "\n",
    ">\\begin{align}\n",
    "Q(\\theta) =& \\prod_i Q_i(\\theta_i) \\\\\n",
    "\\mathcal{L}(Q) =& \\int Q(\\theta) \\log\\left( \\frac{P(D, \\theta)}{Q(\\theta)} \\right) d\\theta \\\\\n",
    "=& \\int Q(\\theta) \\log P(X,\\theta) d\\theta - \\int Q(\\theta) \\log Q(\\theta) d\\theta \\\\\n",
    "=& \\int \\prod_i Q_i(\\theta_i) \\log P(X,\\theta) d\\theta - \\int \\prod_i Q)i(\\theta_i) \\log \\prod_j Q_j(\\theta_j) d\\theta \\\\\n",
    "=& \\int Q_i(\\theta_i) \\prod_{k\\neq i} Q_k(\\theta_k) \\log P(X,\\theta) d\\theta - \\int \\prod_i Q_i(\\theta_i) \\sum_j \\log Q_j(\\theta_j) d\\theta \\\\\n",
    "=& \\int Q_i(\\theta_i) \\int \\prod_{k\\neq i} Q_k(\\theta_k) \\log P(X,\\theta) d\\theta_{\\backslash i} d\\theta_i - \\sum_j \\int \\prod_i Q_i(\\theta_i) \\log Q_j(\\theta_j) d\\theta \\\\\n",
    "=& \\int Q_i(\\theta_i) \\EE{ \\log P(X,\\theta) }_{k\\neq i} d\\theta_i - \\int Q_i(\\theta_i)\\log Q_i(\\theta_i) - \\sum_{j\\neq i} \\int Q_j(\\theta_j) \\log Q_j(\\theta_j) d\\theta \\\\\n",
    "=& \\int Q_i(\\theta_i) \\EE{ \\log P(X,\\theta) }_{k\\neq i} d\\theta_i - \\E{\\log Q_i(\\theta_i)} - \\EE{ \\log p(D,\\theta) }_{j\\neq i} \\\\\n",
    "max\\; Q_i(\\theta_i) \\Rightarrow& \\\\\n",
    "\\log Q_i(\\theta_i) =& - \\int Q_i(\\theta_i) \\EE{ \\log P(X,\\theta) }_{k\\neq i} d\\theta_i + \\EE{ \\log P(D,\\theta) }_{k\\neq i} \\\\\n",
    "Q_i(\\theta_i) =& \\frac{ \\exp \\EE{ \\log P(D,\\theta) }_{k\\neq i}  }{\\int \\exp Q_i(\\theta_i) \\EE{ \\log P(X,\\theta) }_{k\\neq i} d\\theta_i}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. The log-probability (10 points)\n",
    "\n",
    "Write down the log-prob of data and parameters, $\\ln p(\\mathbf{X}, \\mathbf{Z}, \\mathbf{W}, \\mathbf{\\alpha}, \\tau, \\mathbf{\\mu})$, in full detail (where $\\mathbf{X}$ are observed, $\\mathbf{Z}$ is latent; this is different from [Bishop99] who uses $\\mathbf{T}$ and $\\mathbf{X}$ respectively, but $\\mathbf{X}$ and $\\mathbf{Z}$ are consistent with the PRML book and are more common nowadays). Could we use the log-prob to assess the convergence of the variational Bayesian PCA algorithm? If yes, how? If no, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> $$\\begin{align}\n",
    "\\ln p(\\vt{X}, \\vt{Z}, \\vt{W}, \\vt{\\alpha}, \\tau, \\vt{\\mu})\n",
    "=& \\ln p(\\vt{X}) p(\\vt{X}|, \\vt{Z}, \\vt{\\mu}, \\tau)p(\\vt{W}| \\vt{\\alpha})p(\\vt{\\alpha})p(\\vt{\\mu})p(\\tau) \\\\\n",
    "=& \\sum_{n=1}^N  \\lb \\ln p(\\vt{x}_n) + \\ln p(\\vt{x}_n|, \\vt{z}_n, \\vt{\\mu}, \\tau)+ \\ln p(\\vt{W}| \\vt{\\alpha})+ \\ln p(\\vt{\\mu})+ \\ln p(\\vt{\\alpha})+ \\ln p(\\tau) \\rb \\\\\n",
    "=& \\sum_{n=1}^N \\ln \\gaus{\\vt{x}_n|\\vt{0},\\vt{I}_q} + \\sum_{n=1}^N \\ln \\gaus{\\vt{t}_n | \\vt{Wx}_n+\\vt{\\mu},\\tau^{-1}\\vt{I}_{d}} \\\\\n",
    "& + N \\sum_{i=1}^q \\ln \\left ( \\dfrac{\\alpha_i}{2 \\pi} \\right ) ^ {d/2} \\exp \\left \\{  -\\dfrac{1}{2} \\alpha_i||\\vt{w}_i||^2\n",
    "\\right \\}\n",
    "+ N \\ln \\gaus{\\vt{\\mu} | \\vt{0},\\beta^{-1}\\vt{I}_d}\n",
    "+ N \\sum_{i=1}^q \\ln \\Gamma (\\alpha_i|a_{\\alpha},b_{\\alpha})\n",
    "+ N \\ln \\Gamma (\\tau | c_{\\tau}, d_{\\tau})\n",
    "\\end{align}$$\n",
    "\n",
    "> We want to optimise the posterior probability. We could find the posterior from the joint (using bayes theorem), but this is intractable. $Q$ is an approximation of the posterior, with different parameters. Therefore we cannot check the convergence of $Q$ (which is what we do in the bayesian PCA) using the joint $p(\\vt{X}, \\vt{Z}, \\vt{W}, \\vt{\\alpha}, \\tau, \\vt{\\mu})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. The lower bound $\\mathcal{L}(Q)$ (25 points)\n",
    "\n",
    "Derive an expression for the lower bound $\\mathcal{L}(Q)$ of the log-prob $\\ln p(X)$ for Bayesian PCA, making use of the factorization (eq. 12) and the form of the Q-distributions (eq. 16-20) as listed in [Bishop99]. Show your steps. Implement this function.\n",
    "\n",
    "The following result may be useful:\n",
    "\n",
    "For $x \\sim \\Gamma(a,b)$, we have $\\langle \\ln x\\rangle = \\ln b + \\psi(a)$, where $\\psi(a) = \\frac{\\Gamma'(a)}{\\Gamma(a)}$ is the digamma function (which is implemented in numpy.special)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ">$\\begin{align}\n",
    "\\mathcal{L}(W,\\alpha,\\tau,\\mu) =& \\int\\int\\int\\int\\int Q(Z,W,\\alpha\\tau,\\mu) \\log\\left\\{ \\frac{p(X,Z,W,\\alpha,\\tau,\\mu)}{Q(Z,W,\\alpha,\\tau,\\mu)}\\right\\} dZdWd\\alpha d\\tau d\\mu \\\\\n",
    "=& \\E{\\log p(X,Z,W,\\alpha,\\tau,\\mu)} - \\E{\\log p(Z,W,\\alpha,\\tau,\\mu)} \\\\\n",
    "=& \\E{\\log p(X|Z,W,\\mu)} + \\E{\\log p(Z)} + \\E{\\log p(W|\\alpha)} + \\E{\\log p(\\alpha)} + \\E{\\log p(\\tau)} + \\E{\\log p(\\mu)} \\\\&- \\E{\\log Q(Z)} - \\E{\\log Q(W)} - \\E{\\log Q(\\alpha)} - \\E{\\log Q(\\tau)} - \\E{\\log Q(\\mu)}\n",
    "\\end{align}$\n",
    "\n",
    "> Where all the expectations are with respect to the random variables they involve. We will derive these expectations below. (We do often omit the notation with respect to what we take the expectation, this will allways be all the random variable(s) involved.)\n",
    "\n",
    ">$\\begin{align}\n",
    "\\E{\\log p(X|Z,W,\\mu)} &= \\E{\\log \\prod^N_{n=1} \\gaus{x_n|Wz + \\mu, \\tau^{-1}I_d} }  \\\\\n",
    "&= \\sum^N_{n=1} \\E{\\log(2\\pi)^{-\\frac12} + \\log|\\tau^{-1} I_d|^{-\\frac d2} - \\frac12(\\vt{x}_n - \\vt{Wz}_n -\\vt{\\mu})^T\\tau I_d(\\vt{x}_n - \\vt{Wz}_n -\\vt{\\mu})}\\\\\n",
    "&= -\\frac12\\log(2\\pi) -\\E{\\frac d2\\log \\tau^{-d}} -\\frac12 \\sum^N_{n=1} \\E{\\tau}\\E{(\\vt{x}_n - \\vt{Wz}_n -\\vt{\\mu})^T\\ (\\vt{x}_n - \\vt{Wz}_n -\\vt{\\mu} )}\\\\\n",
    "&= -\\frac12\\log(2\\pi) +\\E{\\frac {d^2}2\\log \\tau} \\\\\n",
    "& \\quad -\\frac12 \\E{\\tau} \\sum^N_{n=1} \\E{ \\vt{x}_n^T \\vt{x}_n -2 \\vt{x}_n^T \\lp \\vt{Wz}_n + \\vt{\\mu} \\rp + 2\\vt{z}_n^T\\vt{W}^T\\vt{\\mu}+ \\vt{z}_n^T\\vt{W}^T\\vt{Wz}_n + \\vt{\\mu}^T\\vt{\\mu} }\\\\\n",
    "&= -\\frac12\\log(2\\pi) +\\frac {d^2}2 \\E{\\log \\tau} \\\\\n",
    "& \\quad -\\frac12 \\E{\\tau} \\sum^N_{n=1} \\lp \\E{ \\vt{x}_n^T \\vt{x}_n} -2 \\E{\\vt{x}_n}^T \\lp \\E{\\vt{W}}\\E{\\vt{z}_n} + \\E{\\vt{\\mu}} \\rp + 2\\E{\\vt{z}_n}^T\\E{\\vt{W}}^T\\E{\\vt{\\mu}}+ \\E{\\vt{z}_n^T\\vt{W}^T\\vt{Wz}_n} + \\E{\\vt{\\mu}^T\\vt{\\mu}}  \\rp \\\\\n",
    "&= -\\frac12\\log(2\\pi) +\\frac {d^2}2 \\E{\\log \\tau} \\\\\n",
    "& \\quad -\\frac12 \\E{\\tau} \\sum^N_{n=1} \\lp ||\\vt{x}_n||^2 -2 \\vt{x}_n^T \\lp \\E{\\vt{W}}\\E{\\vt{z}_n} + \\E{\\vt{\\mu}} \\rp + 2\\E{\\vt{z}_n}^T\\E{\\vt{W}}^T\\E{\\vt{\\mu}}+ \\E{\\vt{z}_n^T\\vt{W}^T\\vt{Wz}_n} + \\E{\\vt{\\mu}^T\\vt{\\mu}}  \\rp \n",
    "\\end{align}\n",
    "$\n",
    "$\n",
    "\\begin{align}\n",
    "\\E{\\vt{z}_n^T\\vt{W}^T\\vt{W}\\vt{z}_n} &= \\E{\\vt{z}_n^T\\E{\\vt{W}^T\\vt{W}}_{Q(\\vt{W})}\\vt{z}_n}_{Q(\\vt{z}_n)} \\\\\n",
    "&= Tr \\lp \\E{\\vt{W}^T\\vt{W}}  Cov \\lp \\vt{z}_n \\rp \\rp + \\E{\\vt{z}_n}^T \\E{\\vt{W}^T\\vt{W}} \\E{\\vt{z}_n}\n",
    "&& \\text{(Cookbook 328)} \\\\\n",
    "&= Tr \\lp \\E{\\vt{W}^T\\vt{W}}  \\vt{\\Sigma_z} \\rp + \\E{\\vt{z}_n}^T \\E{\\vt{W}^T\\vt{W}} \\E{\\vt{z}_n} \\\\\n",
    "\\E{\\log p(Z)} &= \\E{\\log \\prod^N_{n=1} \\gaus{\\vt{z_n} | \\vt{0},\\vt{I}_q} } \\\\\n",
    "&= \\sum^N_{n=1} \\E{\\log \\la (2\\pi)^{-\\frac12} |I_q|^{-\\frac q2}\\exp\\lp -\\frac12(\\vt{z}_n-\\vt{0})^T(\\vt{z}_n-\\vt{0})  \\rp \\ra } \\\\\n",
    "&= -\\frac12 \\Big [ N \\log(2\\pi)  +\\sum^N_{n=1} \\E{\\vt{z}_n^T\\vt{z}_n} \\Big ]\\\\\n",
    "\\E{\\log p(W | \\alpha)}\n",
    "&= \\E{ \\ln \\prod_{i=1}^q  \\left ( \\dfrac{\\alpha_i}{2 \\pi} \\right ) ^ {d/2} \\exp \\left \\{  -\\dfrac{1}{2} \\alpha_i||\\vt{w}_i||^2 \\right \\} } \\\\\n",
    "&= \\E{  \\sum_{i=1}^q  \\left \\{\\dfrac{d}{2}\\ln \\alpha_i -\\dfrac{d}{2} \\ln (2 \\pi)   -\\dfrac{1}{2} \\alpha_i||\\vt{w}_i||^2 \\right \\} } \\\\\n",
    "&=  \\dfrac{d}{2} \\sum_{i=1}^q \\E{\\ln \\alpha_i}_{Q(\\alpha_i)} -\\dfrac{d}{2} q \\ln (2 \\pi) -\\dfrac{1}{2} \\sum_{i=1}^q  \\E{\\alpha_i}_{Q(\\alpha_i)} \\E{   ||\\vt{w}_i||^2  }_{Q{\\vt{w}_i}} \\\\\n",
    "&=  \\dfrac{1}{2}\\lb d \\E{\\ln \\vt{\\alpha}} -d q \\ln (2 \\pi) - \\sum_{i=1}^q  \\E{\\alpha_i} \\E{   \\vt{w}_i^T\\vt{w}_i  } \\rb \\\\\n",
    "\\E{\\vt{w}_i} &= \n",
    "\\begin{pmatrix}\n",
    "{m_w^{(1)}}_i \\\\\n",
    "\\vdots \\\\\n",
    "{m_w^{(d)}}_i\n",
    "\\end{pmatrix} =  \\mwtilde && \\text{(we define } \\mwtilde \\text{ for shorter notation)}\\\\\n",
    "\\E{||\\vt{w}_i||^2} &= \\E{\\vt{w}_i^T\\vt{w}_i} = Tr(Var(\\vt{w}_i)) + \\E{\\vt{w}_i}^T\\E{\\vt{w}_i}\n",
    "&&\\text{(318 cookbook)}\\\\\n",
    "&=  \\sum_{j=1}^d var(w_{ij}) + ||\\mwtilde[i]||^2 \\\\\n",
    "&=  Tr(\\vt{\\Sigma_w}) + ||\\mwtilde[i]||^2 \\\\\n",
    "\\E{\\alpha_i} &= \\dfrac{a_{\\alpha}}{b_{\\alpha i}} \\\\\n",
    "\\E{\\log p(\\vt{\\alpha})} &= \\E {\\sum_{i=1}^q \\ln \\Gamma (\\alpha_i|a_{\\alpha},b_{\\alpha})} \\\\\n",
    "&= \\sum_{i=1}^q H\\left[\\Gamma (\\alpha_i|a_{\\alpha},b_{\\alpha})\\right] \\\\\n",
    "&= q \\cdot \\Big( \\ln \\Gamma(a_\\alpha) - (a_\\alpha -1)\\psi(a_\\alpha) - \\ln b_{\\alpha} +a_{\\alpha} \\Big)\\\\\n",
    "\\E{\\log p(\\tau)} &= \\E{\\log \\Gamma (\\tau | c_{\\tau}, d_{\\tau})} \\\\\n",
    "&= H\\left[\\Gamma (\\tau | c_{\\tau}, d_{\\tau})\\right] \\\\\n",
    "&= \\ln \\Gamma(c_\\tau) - (c_\\tau -1)\\psi(c_\\tau) - \\ln d_{\\tau} +c_{\\tau} \\\\\n",
    "\\E{\\log p(\\mu)} &= \\E{\\log \\gaus{\\vt{\\mu} | \\vt{0},\\beta^{-1}\\vt{I}_d} } \\\\\n",
    "&= \\E{\\log (2\\pi)^{-\\frac12} |\\beta^{-1}I_d|^{-\\frac d2}\\exp\\lp -\\frac12(\\mu-0)^T\\beta I_d(\\mu-0) \\rp } \\\\\n",
    "&= \\frac12 \\bigg [ d^2\\log \\beta -\\log(2\\pi)  -\\beta\\E{\\vt{\\mu}^T \\vt{\\mu}} \\bigg ] \\\\\n",
    "\\E{\\log Q(Z)} &= \\E{\\log \\prod^N_{n=1} \\gaus{z_n|m_z^{(n)},\\Sigma_z}} \\\\\n",
    "&= \\sum^N_{n=1} \\E{\\log \\gaus{z_n|m_z^{(n)},\\Sigma_z}} \\\\\n",
    "&= \\sum^N_{n=1} H\\left[\\gaus{x_z|m_z^{(n)},\\Sigma_z}\\right]\n",
    "&& \\text{(entropy)}\\\\\n",
    "&= \\sum^N_{n=1} \\lp \\frac12 \\log |\\Sigma_z| + \\frac q 2(1+\\log(2\\pi)) \\rp\n",
    "&& \\text{(Bishop appendix B)}\\\\\n",
    "&= \\frac{N}{2} \\Big [ \\log |\\Sigma_z| +  q(1+\\log(2\\pi)) \\Big ] \\\\\n",
    "\\E{\\log Q(W)} &= \\E{\\log \\prod^d_{k=1} \\gaus{\\tilde{w}_k|m_w^{(k)},\\Sigma_w}} \\\\\n",
    "&= \\sum^d_{k=1} \\E{\\log \\gaus{\\tilde{w}_k|m_w^{(k)},\\Sigma_w}} \\\\\n",
    "&= \\sum^d_{k=1} H\\left[\\gaus{\\tilde{w}_k|m_w^{(k)},\\Sigma_w}\\right]\n",
    "&& \\text{(entropy)}\\\\\n",
    "&= \\sum^d_{k=1} \\lp \\frac12 \\log |\\Sigma_w| + \\frac q2(1+\\log(2\\pi)) \\rp\n",
    "&& \\text{(Bishop appendix B)}\\\\\n",
    "&= \\dfrac{d}{2} \\Big [ \\log |\\Sigma_w| + q (1+\\log(2\\pi)) \\Big ] \\\\\n",
    "\\E{\\log Q(\\alpha)} &= \\E{\\log \\prod^q_{i=1}\\Gamma(\\alpha_i|\\tilde{a}_\\alpha,\\tilde{b}_{\\alpha})} \\\\\n",
    "&= \\sum_{i=1}^q \\Big( \\ln \\Gamma(\\tilde{a}_\\alpha) - (\\tilde{a}_\\alpha -1)\\psi(\\tilde{a}_\\alpha) - \\ln \\tilde{b}_{\\alpha i} +\\tilde{a}_{\\alpha} \\Big)\\\\\n",
    "\\E{\\log Q(\\tau)} &= \\E{\\log \\Gamma(\\tau|\\tilde{a}_\\tau,\\tilde{b}_\\tau) } \\\\\n",
    "&= \\ln \\Gamma(\\tilde{a}_\\tau) - (\\tilde{a}_\\tau -1)\\psi(\\tilde{a}_\\tau) - \\ln \\tilde{b}_{\\tau} +\\tilde{a}_{\\tau} \\\\\n",
    "\\E{\\log Q(\\mu)} &= \\E{\\log \\gaus{\\mu|m_\\mu,\\Sigma_\\mu}} \\\\\n",
    "&= H\\left[ \\gaus{\\mu|m_\\mu,\\Sigma_\\mu} \\right]\n",
    "&& \\text{(entropy)}\\\\\n",
    "&= \\frac12 \\Big [ \\log |\\Sigma_\\mu| + d(1+\\log(2\\pi)) \\Big ]\n",
    "&& \\text{(Bishop appendix B)}\\\\\n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Optimize variational parameters (50 points)\n",
    "Implement the update equations for the Q-distributions, in the __update_XXX methods. Each update function should re-estimate the variational parameters of the Q-distribution corresponding to one group of variables (i.e. either $Z$, $\\mu$, $W$, $\\alpha$ or $\\tau$).\n",
    "\n",
    "Hint: if you run into numerical instabilities resulting from the gamma function use the gammaln function from numpy.special."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In order to compute the update method, we need the following expectations. We find them by the definition of the expectations of the distributions specified in Bishop 16-20.\n",
    "\n",
    "> For the expectations of $Q(X), Q(\\vt{W}), Q(\\vt{\\alpha})$, we make fact of the use that the distributions of their components are i.i.d. and we can thus take the expectation for their components individually.\n",
    "\n",
    "> $$\n",
    "\\begin{align}\n",
    "\\E{\\tau} &= \\dfrac{\\widetilde{a}_{\\tau}}{\\widetilde{b}_{\\tau}}\\\\\n",
    "\\E{\\vt{z}_n} &= \\vt{m_z}^{(n)}\\\\\n",
    "\\E{\\vt{z}_n\\vt{z}_n^T} &= Cov(\\vt{z}_n) + \\E{\\vt{z}_n}\\E{\\vt{z}_n}^T &&\\text{(321 cookbook)}\\\\\n",
    "&= \\vt{\\Sigma_z} + \\vt{m_z}^{(n)}{\\vt{m_z}^{(n)}}^T \\\\\n",
    "\\E{||\\vt{z}_n||^2} &= \\E{\\vt{z}_n^T\\vt{z}_n} \\\\\n",
    "&= Tr(Var(\\vt{z}_n)) + \\E{\\vt{z}_n}^T\\E{\\vt{z}_n} &&\\text{(318 cookbook)}\\\\\n",
    "&= Tr(\\vt{\\Sigma_z}) + {\\vt{m_z}^{(n)} } ^T \\vt{m_z}^{(n)} \\\\\n",
    "\\E{\\vt{\\mu}} &= \\vt{m_{\\mu}}\\\\\n",
    "\\E{\\vt{\\mu}^T} &= \\E{\\vt{\\mu}}^T = \\vt{m_{\\mu}}^T\\\\ \n",
    "\\E{||\\vt{\\mu}||^2} &= \\E{\\vt{\\mu}^T\\vt{\\mu}} = Tr(Var(\\vt{\\mu})) + \\E{\\vt{\\mu}}^T\\E{\\vt{\\mu}} &&\\text{(318 cookbook)}\\\\\n",
    "&= Tr(\\vt{\\Sigma_{\\mu}})) + \\vt{m_{\\mu}}^T\\vt{m_{\\mu}} \\\\\n",
    "\\E{\\mu_k} &= {m_{\\mu}}_k\\\\\n",
    "\\E{\\vt{\\alpha}} &= \\begin{pmatrix}\n",
    " \\dfrac{ \\widetilde{a}_{\\alpha} }{\\widetilde{b}_{\\alpha 1} }\\\\\n",
    " \\vdots \\\\\n",
    " \\dfrac{ \\widetilde{a}_{\\alpha} }{\\widetilde{b}_{\\alpha q} } \\\\\n",
    " \\end{pmatrix}\n",
    " = \\widetilde{a}_{\\alpha} \\vt{\\tilde{b}}_{\\alpha}^{-1} &&\\text{(elementwise inverse)} \\\\\n",
    " \\E{\\vt{W}}\n",
    " &=\n",
    "  \\begin{pmatrix}\n",
    "\\hline & {\\mw[1]}^T & \\hline\\\\ \n",
    " & \\vdots & \\\\\n",
    "\\hline & {\\mw[d]}^T & \\hline\\\\ \n",
    "\\end{pmatrix} \\\\\n",
    " \\E{\\vt{W}^T} &=  \\E{\\vt{W}}^T \\\\\n",
    " &=\n",
    "  \\begin{pmatrix}\n",
    "\\hline & {\\mw[1]}^T & \\hline\\\\ \n",
    " & \\vdots & \\\\\n",
    "\\hline & {\\mw[d]}^T & \\hline\\\\ \n",
    "\\end{pmatrix} ^T \\\\\n",
    "&=\n",
    " \\begin{pmatrix}\n",
    "\\vline & & \\vline\\\\ \n",
    "\\mw[1] & \\dots & \\mw[d] \\\\\n",
    "\\vline & & \\vline\\\\ \n",
    "\\end{pmatrix}\n",
    " \\\\\n",
    "\\E{\\vt{w}_i} &= \n",
    "\\begin{pmatrix}\n",
    "{m_w^{(1)}}_i \\\\\n",
    "\\vdots \\\\\n",
    "{m_w^{(d)}}_i\n",
    "\\end{pmatrix} =  \\mwtilde && \\text{(we define } \\mwtilde \\text{ for shorter notation)}\\\\\n",
    "\\E{||\\vt{w}_i||^2} &= \\E{\\vt{w}_i^T\\vt{w}_i} = Tr(Var(\\vt{w}_i)) + \\E{\\vt{w}_i}^T\\E{\\vt{w}_i}\n",
    "&&\\text{(318 cookbook)}\\\\\n",
    "&=  \\sum_{j=1}^d var(w_{ij}) + ||\\mwtilde[i]||^2 \\\\\n",
    "&=  Tr(\\vt{\\Sigma_w}) + ||\\mwtilde[i]||^2 \\\\\n",
    "\\lp \\vt{W}^T\\vt{W} \\rp_{ij}\n",
    "&= \\sum_{k=1}^d \\lp \\vt{W}^T\\rp_{ik} W_{kj}\n",
    "=\\sum_{k=1}^d W_{ki} W_{kj}\n",
    "= \\sum_{k=1}^d (\\vt{\\tilde{w}}_k)_i (\\vt{\\tilde{w}}_k)_j\n",
    "=  \\sum_{k=1}^d \\lp \\vt{\\tilde{w}}_k \\vt{\\tilde{w}}_k^T \\rp_{ij}\n",
    "\\\\\n",
    "\\E{ \\vt{W}^T\\vt{W} } &= \\sum_{k=1}^d \\E{ \\vt{\\tilde{w}}_k \\vt{\\tilde{w}}_k^T  }\n",
    "= \\sum_{k=1}^d \\lp \\vt{\\Sigma_w} + \\mw \\mw^T \\rp\n",
    "&&\\text{(321 cookbook)}\\\\\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['f', 'mean', 'cov', 'sum']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "%pylab inline\n",
    "import sys\n",
    "if sys.version_info < (3,):\n",
    "    from __builtin__ import sum\n",
    "else:\n",
    "    from builtins import sum\n",
    "import scipy.special as sp\n",
    "from numpy import linalg as LA\n",
    "\n",
    "def _blob(x, y, area, colour):\n",
    "    \"\"\"\n",
    "    Draws a square-shaped blob with the given area (< 1) at\n",
    "    the given coordinates.\n",
    "    \"\"\"\n",
    "    hs = np.sqrt(area) / 2\n",
    "    xcorners = np.array([x - hs, x + hs, x + hs, x - hs])\n",
    "    ycorners = np.array([y - hs, y - hs, y + hs, y + hs])\n",
    "    plt.fill(xcorners, ycorners, colour, edgecolor=colour)\n",
    "\n",
    "def hinton(W, maxweight=None):\n",
    "    \"\"\"\n",
    "    Draws a Hinton diagram for visualizing a weight matrix. \n",
    "    Temporarily disables matplotlib interactive mode if it is on, \n",
    "    otherwise this takes forever.\n",
    "    \"\"\"\n",
    "    reenable = False\n",
    "    if plt.isinteractive():\n",
    "        plt.ioff()\n",
    "    \n",
    "    plt.clf()\n",
    "    height, width = W.shape\n",
    "    if not maxweight:\n",
    "        maxweight = 2**np.ceil(np.log(np.max(np.abs(W)))/np.log(2))\n",
    "        \n",
    "    plt.fill(np.array([0, width, width, 0]), \n",
    "             np.array([0, 0, height, height]),\n",
    "             'gray')\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.axis('equal')\n",
    "    for x in xrange(width):\n",
    "        for y in xrange(height):\n",
    "            _x = x+1\n",
    "            _y = y+1\n",
    "            w = W[y, x]\n",
    "            if w > 0:\n",
    "                _blob(_x - 0.5,\n",
    "                      height - _y + 0.5,\n",
    "                      min(1, w/maxweight),\n",
    "                      'white')\n",
    "            elif w < 0:\n",
    "                _blob(_x - 0.5,\n",
    "                      height - _y + 0.5, \n",
    "                      min(1, -w/maxweight), \n",
    "                      'black')\n",
    "    if reenable:\n",
    "        plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def p_norm(X, p=2, axis=0):\n",
    "    \"\"\" Returns the p-norm witouth normalisation ||x_n||^p where n is taken over the specified axis \"\"\"\n",
    "    return np.power(LA.norm(X, ord=p, axis=axis, keepdims=True), p)\n",
    "\n",
    "# a constant that reoccurs often\n",
    "LN2PI =  np.log(2 * np.pi)\n",
    "\n",
    "class BayesianPCA(object):\n",
    "    \n",
    "    def __init__(self, d, N, q=None, a_alpha=10e-3, b_alpha=10e-3, a_tau=10e-3, b_tau=10e-3, beta=10e-3):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        q = q or d\n",
    "        \n",
    "        self.d = d # number of dimensions\n",
    "        self.q = q # max number of components        \n",
    "        self.N = N # number of data points\n",
    "        \n",
    "        # Hyperparameters\n",
    "        self.a_alpha = a_alpha\n",
    "        self.b_alpha = b_alpha\n",
    "        self.a_tau = a_tau\n",
    "        self.b_tau = b_tau\n",
    "        self.beta = beta\n",
    "\n",
    "        # Variational parameters\n",
    "        self.means_z = np.random.randn(q, N) # called x in bishop99\n",
    "        self.sigma_z = np.random.randn(q, q)\n",
    "        self.mean_mu = np.random.randn(d, 1)\n",
    "        self.sigma_mu = np.random.randn(d, d)\n",
    "        self.means_w = np.random.randn(q, d) #the means of rows of W are columns here (each column is m_n)\n",
    "                                             #note, this is the transposed definition of <W>\n",
    "        self.sigma_w = np.random.randn(q, q)\n",
    "        self.a_alpha_tilde = np.abs(np.random.randn(1))\n",
    "        self.bs_alpha_tilde = np.abs(np.random.randn(q, 1))\n",
    "        self.a_tau_tilde = np.abs(np.random.randn(1))\n",
    "        self.b_tau_tilde = np.abs(np.random.randn(1))\n",
    "        \n",
    "        self.__update_E_w()\n",
    "        self.__update_E_zn()\n",
    "        self.__update_E_mu()\n",
    "        self.__update_E_wi()\n",
    "        self.__update_E_znW()\n",
    "        self.__update_E_alpha()\n",
    "        self.__update_E_tau()        \n",
    "        \n",
    "    # expectation updates\n",
    "    def __update_E_w(self): \n",
    "        self.E_W = self.means_w\n",
    "        self.E_W_inner = np.einsum(\"ik,jk->ij\", self.means_w, self.means_w) + self.d * self.sigma_w\n",
    "\n",
    "    def __update_E_zn(self):\n",
    "        self.E_zn = self.means_z\n",
    "        self.E_zn_inner = (self.sigma_z.trace() + p_norm(self.E_zn)).T\n",
    "        self.E_zn_outer = np.array([self.sigma_z + np.dot(self.means_z[:,[n]], self.means_z[:,[n]].T) for n in range(self.N)])\n",
    "\n",
    "    def __update_E_mu(self):\n",
    "        self.E_mu = self.mean_mu\n",
    "        self.E_mu_inner = (self.sigma_mu.trace() + p_norm(self.mean_mu))[0]\n",
    "\n",
    "    def __update_E_wi(self):\n",
    "        self.E_wi = self.means_w.T\n",
    "        self.E_wi_inner = (self.sigma_w.trace() + p_norm(self.E_wi)).T\n",
    "\n",
    "    def __update_E_znW(self):\n",
    "        self.E_znW_inner = self.E_W_inner.dot(self.sigma_z).trace() +  np.diag(self.means_z.T.dot(self.E_W_inner).dot(self.means_z)).T\n",
    "\n",
    "    def __update_E_alpha(self):\n",
    "        self.E_alpha = self.a_alpha_tilde / self.bs_alpha_tilde\n",
    "        self.E_lnp_alpha = self.q * (sp.gammaln(self.a_alpha) - (self.a_alpha - 1)*sp.digamma(self.a_alpha) - np.log(self.b_alpha) + self.a_tau)\n",
    "        self.E_lnQ_alpha = (sp.gammaln(self.a_alpha_tilde) - (self.a_alpha_tilde - 1)*sp.digamma(self.a_alpha_tilde) \\\n",
    "                             - np.log(self.bs_alpha_tilde) + self.a_tau_tilde).sum()\n",
    "\n",
    "    def __update_E_tau(self):\n",
    "        self.E_tau = self.a_tau_tilde / self.b_tau_tilde\n",
    "        self.E_lnp_tau = sp.gammaln(self.a_tau) - (self.a_tau - 1)*sp.digamma(self.a_tau) - np.log(self.b_tau) + self.a_tau\n",
    "        self.E_lnQ_tau = sp.gammaln(self.a_tau_tilde) - (self.a_tau_tilde - 1)*sp.digamma(self.a_tau_tilde) \\\n",
    "                            - np.log(self.b_tau_tilde) + self.a_tau_tilde\n",
    "    \n",
    "    #parameter updates\n",
    "    def __update_z(self, X):        \n",
    "        # Σ_z = [ I + E(τ) * E(W^T * W) ]^{−1}\n",
    "        self.sigma_z = LA.inv(np.eye( self.q ) + self.E_tau * self.E_W_inner)\n",
    "        \n",
    "        # m^{(n)}_z = E(τ) * Σ_z * E(W^T) * (x_n − E(µ) )        \n",
    "        self.means_z = self.E_tau * self.sigma_z.dot(self.E_W).dot(X - self.E_mu)\n",
    "                \n",
    "        # update expectations\n",
    "        self.__update_E_zn()\n",
    "        self.__update_E_znW()\n",
    "    \n",
    "    def __update_mu(self,X):\n",
    "        # Σµ = (β + N * E(τ) )^{-1} * I\n",
    "        self.sigma_mu = 1.0 / (self.beta + self.N*self.E_tau) * np.eye(self.d)\n",
    "        \n",
    "        # m_µ = E(τ) * Σ_µ * \\sum^N_{n=1} ( (x_n − E(W) * E(z_n))\n",
    "        self.mean_mu = self.E_tau * self.sigma_mu.dot((X - self.E_W.T.dot(self.E_zn)).sum(1, keepdims=True))\n",
    "        \n",
    "        # update expectations\n",
    "        self.__update_E_mu()\n",
    "        \n",
    "    def __update_w(self, X):\n",
    "        # Σ_w = [ diag(E(α)) + E(τ) * \\sum^N_{n=1} E(z_n * z_n^T) ]^{−1}\n",
    "        self.sigma_w = LA.inv( np.diag(self.E_alpha[:,0]) + self.E_tau*self.E_zn_outer.sum() )\n",
    "        \n",
    "        # m^{(k)}_w = E(τ) * Σ_w * \\sum^N_{n=1} E(z_n) * (x_{nk} − E(µ_k) )\n",
    "        self.means_w = self.E_tau * self.sigma_w.dot(self.E_zn.dot(X.T - self.E_mu.T))\n",
    "        \n",
    "        # update expectations\n",
    "        self.__update_E_w()\n",
    "        self.__update_E_wi()\n",
    "        self.__update_E_znW()\n",
    "    \n",
    "    def __update_alpha(self):\n",
    "        # ã_α = a_α + d/2\n",
    "        self.a_alpha_tilde = self.a_alpha + (0.5 * self.d)\n",
    "        \n",
    "        # ~b_{αi} = b_α + E( ||w_i||^2 ) / 2\n",
    "        self.bs_alpha_tilde = (self.b_alpha + (0.5 * self.E_wi_inner) )\n",
    "\n",
    "        # update expectations\n",
    "        self.__update_E_alpha()\n",
    "\n",
    "    def __update_tau(self, X):\n",
    "        # ã_τ = a_τ + N*d/2\n",
    "        self.a_tau_tilde = self.a_tau + (0.5 * self.N * self.d)\n",
    "        \n",
    "        # ~b_τ = b_τ + 1/2 \\sum^N_{n=1} [ ||x_n||^2 + E(||µ||^2) + Tr( E(W^T * W) * E(z_n * z_n^T) ) \n",
    "        #          + 2*E(µ^T)*E(W)*E(z_n) −2*x_n^T*E(W)*E(z_n) − 2x_n^T E(µ) ]\n",
    "        self.b_tau_tilde = self.b_tau \\\n",
    "                            + 0.5 * (p_norm(X).sum()\n",
    "                                         + self.N*self.E_mu_inner \\\n",
    "                                         + self.E_W_inner.dot(self.E_zn_outer).trace(axis2=2).sum() \\\n",
    "                                         + 2*self.E_mu.T.dot(self.E_W.T).dot(self.E_zn).sum() \\\n",
    "                                         - 2*X.T.dot(self.E_W.T).dot(self.E_zn).trace() \\\n",
    "                                         - 2*X.T.dot(self.E_mu).sum()\n",
    "                                     )\n",
    "        \n",
    "        # update expectations\n",
    "        self.__update_E_tau()\n",
    "\n",
    "    def L(self, X):\n",
    "        L = 0.0\n",
    "        \n",
    "        #+ ⟨logp(X|Z,W,μ)⟩  \n",
    "        L += (-0.5) * self.E_tau * \\\n",
    "             ( p_norm(X) - 2*np.diag(X.T.dot(self.E_W.T.dot(self.E_zn)+self.E_mu)).T \\\n",
    "               + 2*self.E_zn.T.dot(self.E_W).dot(self.E_mu) \\\n",
    "               + self.E_znW_inner+self.E_mu_inner ).sum()\n",
    "\n",
    "        #+⟨logp(Z)⟩\n",
    "        L += -0.5 * (self.N*LN2PI + self.E_zn_inner.sum())\n",
    "        \n",
    "        #+⟨logp(W|α)⟩\n",
    "        L += 0.5*( self.d*self.E_lnp_alpha \\\n",
    "                    - self.d*self.q*LN2PI \\\n",
    "                    - (self.E_alpha*self.E_wi_inner).sum() )\n",
    "        \n",
    "        #+⟨logp(α)⟩\n",
    "        L += self.E_lnp_alpha\n",
    "        \n",
    "        #+⟨logp(τ)⟩\n",
    "        L += self.E_lnp_tau\n",
    "        \n",
    "        #+⟨logp(μ)⟩\n",
    "        L += 0.5*( np.power(self.d,2)*np.log(self.beta) \\\n",
    "                    - LN2PI \n",
    "                    - self.beta*self.E_mu_inner )\n",
    "        \n",
    "        #−⟨logQ(Z)⟩\n",
    "        L -= 0.5*self.N * (LA.slogdet(self.sigma_z)[1]\n",
    "                           + self.q*(1+LN2PI))\n",
    "        \n",
    "        #−⟨logQ(W)⟩\n",
    "        L -= 0.5*self.d * (LA.slogdet(self.sigma_w)[1]\n",
    "                           + self.q*(1+LN2PI))\n",
    "    \n",
    "        #−⟨logQ(α)⟩\n",
    "        L-= self.E_lnQ_alpha\n",
    "        \n",
    "        #−⟨logQ(τ)⟩\n",
    "        L-= self.E_lnQ_tau\n",
    "        \n",
    "        #−⟨logQ(μ)⟩\n",
    "        L-=  0.5 * (LA.slogdet(self.sigma_mu)[1]\n",
    "                     + self.d*(1+LN2PI))        \n",
    "        return L\n",
    "    \n",
    "    def __sanity_check(self, i):\n",
    "        \"\"\" Some usefull checks for debugging \"\"\"\n",
    "        def invertable(X):\n",
    "            return LA.matrix_rank(X) == X.shape[0]\n",
    "        def debug_assert(assertion, *printargs):\n",
    "            if not assertion:\n",
    "                print('ERROR AT ITERATION %i' % i)\n",
    "                print(printargs)\n",
    "                assert assertion, printargs[0]\n",
    "        \n",
    "        debug_assert(self.b_alpha >= 0, 'b_alpha > 0')\n",
    "        debug_assert((self.bs_alpha_tilde >= 0).all(), 'bs_alpha_tilde > 0')        \n",
    "        debug_assert(self.b_tau >= 0, 'b_tau > 0')\n",
    "        debug_assert(self.b_tau_tilde >= 0, 'b_tau_tilde > 0')\n",
    "        debug_assert(invertable(np.eye( self.q ) + self.E_tau * self.E_W_inner),\n",
    "                    ('Non-inveratable sigma_z', self.E_tau, self.E_W_inner))\n",
    "        debug_assert(invertable(np.diag(self.E_alpha[:,0]) + self.E_tau*self.E_zn_outer.sum() ),\n",
    "                     ('Non-inveratable sigma_w', np.diag(self.E_alpha[:,0]),self.E_tau,self.E_zn_outer,self.E_zn_outer.sum()))\n",
    "\n",
    "    \n",
    "    def fit(self, X, max_iter=100, convergence_rate=1e-4, debug=False):\n",
    "        p1,p2 = -np.inf, self.L(X)\n",
    "        u = [p1,p2]\n",
    "        du = [p1-p2]\n",
    "        ddu = []\n",
    "        for i in range(max_iter):\n",
    "            \n",
    "                if debug: self.__sanity_check(i)\n",
    "                self.__update_mu(X)\n",
    "                if debug: self.__sanity_check(i)                \n",
    "                self.__update_w(X)\n",
    "                if debug: self.__sanity_check(i)                \n",
    "                self.__update_z(X)\n",
    "                if debug: self.__sanity_check(i)                \n",
    "                self.__update_alpha()\n",
    "                if debug: self.__sanity_check(i)                \n",
    "                self.__update_tau(X)\n",
    "                if debug: self.__sanity_check(i)\n",
    "                \n",
    "                n = self.L(X)\n",
    "                #if debug: assert(u[-1] < n)\n",
    "                u.append(n)\n",
    "                du.append(p2-n)\n",
    "                ddu.append(p1-2*p2+n)\n",
    "                p1 = p2\n",
    "                p2 = n\n",
    "                \n",
    "                if abs(du[-1]) < convergence_rate:\n",
    "                    print('Converged in %i iterations!' % i)\n",
    "                    break\n",
    "        return np.array(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Learning algorithm (10 points)\n",
    "Implement the learning algorithm described in [Bishop99], i.e. iteratively optimize each of the Q-distributions holding the others fixed.\n",
    "\n",
    "What would be a good way to track convergence of the algorithm? Implement your suggestion.\n",
    "\n",
    "Test the algorithm on some test data drawn from a Gaussian with different variances in orthogonal directions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "cov: [[5 0 0 0 0 0 0 0 0 0]\n",
      " [0 4 0 0 0 0 0 0 0 0]\n",
      " [0 0 3 0 0 0 0 0 0 0]\n",
      " [0 0 0 2 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEPCAYAAABiCi5wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwg0wjHADDCPcAMMIN8Aw/w+iH/m0ZiLTLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13b3481d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged in 13 iterations!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEZCAYAAABB4IgrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X2cXVV97/HPNwkJEwiEBA1JCBB1aE2rFlCC1wdORWJu\nbyXYIsS2kGquvmrqQ61agd5CptxrodoibS/0VUsgSSUSgQv0SkMiOFdai8EnjEYktAYykycc8qBA\nICG/+8deJ9k5zCSEmX32nnO+79frvM4+a++9zm9PMvM7a5211lZEYGZmVqQRZQdgZmatz8nGzMwK\n52RjZmaFc7IxM7PCOdmYmVnhnGzMzKxwTjZmZlY4JxszMyuck41ZhUkaVXYMZkPBycYMkDRN0h2S\ntkr6maS/VeZ/SFovaYukxZKOScefImmvpEskPS7pSUmXp31TJD0j6bhc/aelY0am1x+QtFbSU5JW\nSDopd+xeSQskrQN+ksr+RNJGST2S/ns65lVp3xhJn09xbJZ0g6Qj075aOueP0zVslPT7uffqkPRX\n6Rq3S3ogd+5Zkr4paZuk70s6u+h/B2tdTjbW9lIC+L/AT4GTgSnAl4H3A/OAGvAq4Gjg7xpOfwtw\nKnAOcIWkX4qIjcC/A7+dO+53gK9ExAuS5gCXAe8BjgceAJY11DsHeBMwQ9Js4BPpPTpTPHlXA68B\n3pCepwJX5PZPAo5J1zUf+N+Sjk37Pg+cBrwZmAB8GtgraWr6mfx5RBwHfAq4XdLx/f0MzQ4pIvzw\no60fZH9otwIjGsrvA/4g9/pU4HmyD2mnAHuBKbn93wIuTNvzgfvStoAngLem1/8CfCB33gjgaWBa\ner0XqOX2LwL+V+71q9Mxr0p1/wJ4VcP1/GfargHP5K8N2AKcmd73GeB1/fxMPgMsaShbAVxS9r+X\nH8Pz4ZaNGUwDHo+IvQ3lk4HHc6+fAEaRtRTqNue2nyFr/QDcAbxZ0gnA24G9EfGvad/JwHWpe2ob\n0JfKp+bq2tAQR/51T277FcBY4Du5+v6FrMVU19dwbfU4jweOBP6DFzsZeG+9zlTvW4AT+jnW7JD8\n5aNZ9of8JEkjI+KFXPlGshZM3UnAHrKWwUkcRERsk7QSuAiYwYHdZE8AV0VEY9fZAVXktjeRJcS6\n/PbPgGeBGRGx6WAx9eNnwC6yrrcfNOx7AlgaER86zDrN+uWWjVnW/bUJuFrSWElHSnoLWYL4RBoM\ncDTwWeDL/bSA8pTbvoXsO5/fTtt1fw9cLmkGgKRjJb33IHUuB94v6ZcljQX+rL4jxfJF4AuSXpHq\nmypp1qEuOp27CPhrSZMljZT0ZkmjgX8C3i1pVio/Mg02mHrwWs3652RjbS/90X032Sf8J8haOu8l\n+0O8FPgG8J9k3U8fzZ/aX3W57btTnZsiYk3u/e4ErgG+LGkHsAZ410D1RsQK4G+ArwOPkg0+AHgu\nPX8GeAx4MNW3iuz7pYPFWfep9P4PkXXn/QXZ9zs9ZIMULif7PusJ4JP4b4a9TIoo7uZpkhYB/w3Y\nGhGvS2Vnko3oOYKsS2JBRDyU9l0GfAB4AfhYRKxM5WcAN5P1L98TER9P5WOAJcDpZL8oF0XE42nf\nPOBPUyj/MyKWFHahZk0k6bVkCWL0IVpZZpVR9KeUm4DZDWV/CfxZRJxGNjzzLwFSl0K9f3s2cL2k\nepfEDcD8iOgEOtNQUMhG/PSl8mvJPi0iaUKq+8z0uFLS+GIu0ax4kt6T5tMcR/b//G4nGhtOCk02\nEfEAsK2heBNQH+M/HuhN23OAZRGxOyLWk3ULzJQ0GRgXEavTcUuA89P2ecDitH072TwEyLokVkbE\n9ojYTtat0Jj0zIaTD5ENTHgM2A18uNxwzA5PGaPRLgX+VdLnyZLdm1P5FODB3HE9ZENBd3PgUM9e\n9g8RnUoaEhoReyTtkDQx1dXTT11mw1JE/NeyYzAbjDK+7LuR7PuYk8hmRS8qIQYzM2uiMlo2Z0bE\nO9P2bcA/pu1eDpw/cCJZi6Q3bTeW1885CdiobMHCYyOiT1IvBy7pMQ24v79gJBU3QsLMrEVFhA59\n1H5ltGweyy3o9w6yoZyQDROdK2m0pOlka0CtjojNwE5JM9OAgYuBu3LnzEvbF5AtLwKwEpglaXz6\nQvVc4N6BAhqq5Rj27AkWLhz6ZR6uvPLK0peacJyO03E6zvrj5Si0ZSNpGXA2cLykDWQjxD5EthDg\nGLKZzx8CiIi1kpYDa9k/JLp+VQvIhj53kA19XpHKbwSWptVx+4C5qa6nJF1FNncAoCuygQKFGjEC\nPvc5+MQn4Jhjin43M7Pho9BkExHvG2DXzAGO/yzZLO3G8u8Ar+un/DngwgHquols6HXTSDB1Kmzc\n6GRjZpbn2cBDbMqULNkMpVqtNrQVFsRxDi3HObQcZ7kKXUFgOJAUQ/kz+N3fhdmz4eKLh6xKM7NK\nkUQMgwECLa3ejWZmZvs52QyxIrrRzMyGOyebITZ1KvT2Hvo4M7N24mQzxNyyMTN7MSebITZlils2\nZmaNPBptiEejPfdcNsfm2WezSZ5mZq3Go9EqYMwYGDcO+vrKjsTMrDqcbArgrjQzswM52RTAc23M\nzA7kZFMAj0gzMzuQk00BPNfGzOxATjYFcMvGzOxATjYF8AABM7MDOdkUwAMEzMwO5GRTAHejmZkd\nyCsIDPEKAgAvvAAdHfD003DEEUNatZlZ6byCQEWMHAmvfCVs3lx2JGZm1eBkUxAPEjAz28/JpiAe\nJGBmtp+TTUE8SMDMbD8nm4K4G83MbL9Ck42kRZK2SFrTUP5RST+W9ENJ1+TKL5O0TtIjkmblys+Q\ntCbtuy5XPkbSran8QUkn5/bNk/RoelxS5HX2x91oZmb7Fd2yuQmYnS+Q9OvAecDrI+JXgc+n8hnA\nRcCMdM71kupD624A5kdEJ9ApqV7nfKAvlV8LXJPqmgBcAZyZHldKGl/YVfbD3WhmZvsVmmwi4gFg\nW0Pxh4G/iIjd6ZgnU/kcYFlE7I6I9cBjwExJk4FxEbE6HbcEOD9tnwcsTtu3A+ek7XcBKyNie0Rs\nB1bRkPSK5sU4zcz2K+M7m07g7anbq1vSG1P5FKAnd1wPMLWf8t5UTnreABARe4AdkiYepK6mccvG\nzGy/USW953ERcZakNwHLgVeVEMc+Cxcu3Lddq9Wo1WqDrnP8eHj++WwVgaOOGnR1Zmal6e7upru7\ne1B1lJFseoA7ACLiIUl7JR1P1mKZljvuxHRsb9puLCftOwnYKGkUcGxE9EnqBWq5c6YB9w8UUD7Z\nDBVpf+ums3PIqzcza5rGD+FdXV2HXUcZ3Wh3Au8AkHQqMDoifgbcDcyVNFrSdLLuttURsRnYKWlm\nGjBwMXBXqutuYF7avgC4L22vBGZJGi/pOOBc4N4mXNsB3JVmZpYptGUjaRlwNjBR0gayEWKLgEVp\nOPTzwCUAEbFW0nJgLbAHWJBbIXMBcDPQAdwTEStS+Y3AUknrgD5gbqrrKUlXAQ+l47rSQIGm8lwb\nM7OMV30uYNXnuk9+EiZPhk99qpDqzcxK4VWfK8YtGzOzjJNNgbyKgJlZxsmmQB4gYGaWcbIpkLvR\nzMwyHiBQ4ACBZ56BCRPg2WezeTdmZq3AAwQqZuxY6OiAbY2rw5mZtRknm4K5K83MzMmmcB6RZmbm\nZFM4t2zMzJxsCueWjZmZk03hPNfGzMzJpnDuRjMzc7IpnLvRzMycbArnbjQzM68gUOgKAgC7d2e3\nhX7mGRhVxn1RzcyGmFcQqKAjjoCJE2Hr1rIjMTMrj5NNE3iQgJm1OyebJvAgATNrd042TeBBAmbW\n7pxsmsDdaGbW7pxsmsDdaGbW7pxsmsAtGzNrd042TeDvbMys3RWabCQtkrRF0pp+9n1S0l5JE3Jl\nl0laJ+kRSbNy5WdIWpP2XZcrHyPp1lT+oKSTc/vmSXo0PS4p8joPxd1oZtbuim7Z3ATMbiyUNA04\nF3g8VzYDuAiYkc65XlJ9huoNwPyI6AQ6JdXrnA/0pfJrgWtSXROAK4Az0+NKSeOH/vJemokT4emn\n4dlny4rAzKxchSabiHgA2NbPrr8G/qShbA6wLCJ2R8R64DFgpqTJwLiIWJ2OWwKcn7bPAxan7duB\nc9L2u4CVEbE9IrYDq+gn6TWLBJMnw6ZNZUVgZlaupn9nI2kO0BMRP2jYNQXoyb3uAab2U96byknP\nGwAiYg+wQ9LEg9RVGn9vY2btrKlLQ0oaC1xO1oW2r7iZMfRn4cKF+7ZrtRq1Wm3I38Mj0sxsuOru\n7qa7u3tQdTR7HeJXA6cAD6evY04EviNpJlmLZVru2BPJWiS9abuxnLTvJGCjpFHAsRHRJ6kXqOXO\nmQbcP1BQ+WRTFA8SMLPhqvFDeFdX12HX0dRutIhYExGTImJ6REwnSxqnR8QW4G5grqTRkqYDncDq\niNgM7JQ0Mw0YuBi4K1V5NzAvbV8A3Je2VwKzJI2XdBxZS+replzkANyyMbN2VmjLRtIy4GxgoqQN\nwBURcVPukH03komItZKWA2uBPcCC3I1mFgA3Ax3APRGxIpXfCCyVtA7oA+amup6SdBXwUDquKw0U\nKM2UKfD975cZgZlZeXzztIJvnlb39a9DVxcMstvTzKx0vnlahbkbzczamZNNk9SHPrd5Q9LM2pST\nTZOMGwcjR8LOnWVHYmbWfE42TeSuNDNrV042TeS5NmbWrpxsmsgtGzNrV042TeT10cysXTnZNJG7\n0cysXTnZNJG70cysXTnZNJFbNmbWrpxsmsgtGzNrV14brUlrowE8/zwcfTTs2gUjnObNbJjy2mgV\nN3o0jB8PTz5ZdiRmZs3lZNNk7kozs3bkZNNknmtjZu3IyabJPCLNzNqRk02TuRvNzNqRk02TuWVj\nZu3IyabJ3LIxs3bkZNNkHiBgZu3IyabJ3I1mZu3IKwg0cQUBgL174cgj4ec/hzFjmva2ZmZDxisI\nDAMjRsCkSbB5c9mRmJk1T6HJRtIiSVskrcmVfU7SjyU9LOkOScfm9l0maZ2kRyTNypWfIWlN2ndd\nrnyMpFtT+YOSTs7tmyfp0fS4pMjrPFxTp3qQgJm1l6JbNjcBsxvKVgK/EhFvAB4FLgOQNAO4CJiR\nzrleUr2ZdgMwPyI6gU5J9TrnA32p/FrgmlTXBOAK4Mz0uFLS+GIu8fB5kICZtZtCk01EPABsayhb\nFRF708tvASem7TnAsojYHRHrgceAmZImA+MiYnU6bglwfto+D1ictm8Hzknb7wJWRsT2iNgOrOLF\nSa80HiRgZu2m7O9sPgDck7anAD25fT3A1H7Ke1M56XkDQETsAXZImniQuirBc23MrN2MKuuNJf0p\n8HxE3FJWDHULFy7ct12r1ajVaoW+35QpsHZtoW9hZjZkuru76e7uHlQdpSQbSb8P/Ab7u70ga7FM\ny70+kaxF0sv+rrZ8ef2ck4CNkkYBx0ZEn6ReoJY7Zxpw/0Dx5JNNM7gbzcyGk8YP4V1dXYddR9O7\n0dKX+58G5kTErtyuu4G5kkZLmg50AqsjYjOwU9LMNGDgYuCu3Dnz0vYFwH1peyUwS9J4SccB5wL3\nFnphh8HdaGbWbgpt2UhaBpwNHC9pA3Al2eiz0cCqNNjs3yNiQUSslbQcWAvsARbkZlsuAG4GOoB7\nImJFKr8RWCppHdAHzAWIiKckXQU8lI7rSgMFKsGj0cys3XgFgSavIAAQAUcfnU3sHDeuqW9tZjZo\nXkFgmJDcujGz9uJkUxIPEjCzduJkUxIPEjCzduJkUxJ3o5lZO3GyKYm70cysnTjZlMTdaGbWTpxs\nSuJuNDNrJ042JfE9bcysnRwy2UiaKOmohrK3STqyuLBa3+TJsGlTNsHTzKzVvZSWzVrgCw1lm8iW\nkLGXqaMjW0Wgr6/sSMzMivdSks31EfHBfEFEPEZ2B0wbBA8SMLN28VKSzdckfVbSvpuPSRpBdvtm\nGwQPEjCzdnHIVZ8j4t8k7QL+XtIE4Ktk94bx7b8GyYMEzKxdvKTRaBHxnYh4N/BbwEZgIfB4gXG1\nBbdszKxdHNbQ54jYAtwbEbOBbxQTUvtwsjGzdvFy5tl8FSAivjrEsbQdd6OZWbt4OcnmsG6YYwNz\ny8bM2sXLSTZfHPIo2pQX4zSzduHbQpdwW+i6PXuyyZ3PPANHHFFKCGZmh823hR5mRo2CV7wCtmwp\nOxIzs2I52ZTMgwTMrB042ZTMgwTMrB042ZTMycbM2kGhyUbSIklbJK3JlU2QtErSo5JWShqf23eZ\npHWSHpE0K1d+hqQ1ad91ufIxkm5N5Q9KOjm3b156j0clXVLkdQ6Gu9HMrB0U3bK5CZjdUHYpsCoi\nTgXuS6+RNAO4iGyBz9nA9ZLqox1uAOZHRCfQKale53ygL5VfC1yT6poAXEG2MvWZwJX5pFYlbtmY\nWTsoNNlExAPAtobi84DFaXsxcH7angMsi4jdEbEeeAyYKWkyMC4iVqfjluTOydd1O3BO2n4XsDIi\ntkfEdmAVL056leC5NmbWDsr4zmZSWmMNYAswKW1PAXpyx/UAU/sp703lpOcNABGxB9ghaeJB6qoc\n39PGzNrBIW8xUKSICEmlzypduHDhvu1arUatVmvae7sbzcyqrru7m+7u7kHVUUay2SLphIjYnLrI\ntqbyXmBa7rgTyVokvWm7sbx+zknARkmjgGMjok9SL1DLnTON7B48/conm2abMAGefTZbRWDs2NLC\nMDMbUOOH8K6ursOuo4xutLuBeWl7HnBnrnyupNGSpgOdwOqI2AzslDQzDRi4GLirn7ouIBtwALAS\nmCVpvKTjgHOBe4u8qJdLcuvGzFpfoS0bScuAs4HjJW0gGyF2NbBc0nxgPXAhQESslbSc7A6ge4AF\nuUXLFgA3Ax3APRGxIpXfCCyVtA7oA+amup6SdBXwUDquKw0UqKT6IIHXvKbsSMzMiuGFOEtciLPu\noovg/PPhfe8rNQwzs5fEC3EOU+5GM7NW52RTAV5FwMxanZNNBbhlY2atzsmmApxszKzVOdlUgLvR\nzKzVeTRaBUajPf00HH98NrFThzW+w8ys+TwabZg66igYMwa2V3YmkJnZ4DjZVIQX5DSzVuZkUxEe\nJGBmrczJpiI8SMDMWpmTTUW4ZWNmrczJpiKcbMyslTnZVIS70cyslTnZVIRbNmbWypxsKsItGzNr\nZV5BoAIrCADs3p3dFnrXLhg5suxozMwG5hUEhrEjjoAJE2Dr1rIjMTMbek42FeKuNDNrVU42FeJB\nAmbWqpxsKsTJxsxalZNNhbgbzcxalZNNhbhlY2atysmmQtyyMbNWVVqykXSZpB9JWiPpFkljJE2Q\ntErSo5JWShrfcPw6SY9ImpUrPyPVsU7SdbnyMZJuTeUPSjq52dd4uNyyMbNWVUqykXQK8EHg9Ih4\nHTASmAtcCqyKiFOB+9JrJM0ALgJmALOB66V9N1C+AZgfEZ1Ap6TZqXw+0JfKrwWuacKlDYqTjZm1\nqrJaNjuB3cBYSaOAscBG4DxgcTpmMXB+2p4DLIuI3RGxHngMmClpMjAuIlan45bkzsnXdTtwTnGX\nMzSOPx5+/vNsFQEzs1ZSSrKJiKeAvwKeIEsy2yNiFTApIrakw7YAk9L2FKAnV0UPMLWf8t5UTnre\nkN5vD7BD0oShv5qhM2IEnHACbNpUdiRmZkNrVBlvKunVwB8BpwA7gK9I+r38MRERkpqyaNnChQv3\nbddqNWq1WjPetl/1rrTp00sLwczsAN3d3XR3dw+qjlKSDfBG4JsR0Qcg6Q7gzcBmSSdExObURVZf\nKawXmJY7/0SyFk1v2m4sr59zErAxddUdm1pUL5JPNmXziDQzq5rGD+FdXV2HXUdZ39k8ApwlqSN9\n0f9OYC3wz8C8dMw84M60fTcwV9JoSdOBTmB1RGwGdkqameq5GLgrd069rgvIBhxUngcJmFkrKqVl\nExEPS1oCfBvYC3wX+AdgHLBc0nxgPXBhOn6tpOVkCWkPsCB3X4AFwM1AB3BPRKxI5TcCSyWtA/rI\nRrtVnls2ZtaKfD+bitzPpm7pUlixAr70pbIjMTPrn+9n0wLcjWZmrcjJpmLcjWZmrcjJpmLqLZsK\n9eyZmQ2ak03FjBuXPe/cWW4cZmZDycmmYqSsK83f25hZK3GyqSAPEjCzVuNkU0EeJGBmrcbJpoLc\nsjGzVuNkU0FONmbWapxsKsjdaGbWapxsKsgtGzNrNU42FTRlils2ZtZavBBnxRbiBHjuuWxy565d\n2d07zcyqxAtxtogxY+CYY+BnPys7EjOzoeFkU1EeJGBmrcTJpqI8SMDMWomTTUU52ZhZK3GyqSh3\no5lZK3GyqSi3bMyslTjZVJTn2phZK3GyqSjf08bMWomTTUW5G83MWolXEKjgCgIAL7wAHR3wi1/A\n6NFlR2Nmtt+wWkFA0nhJt0n6saS1kmZKmiBplaRHJa2UND53/GWS1kl6RNKsXPkZktakfdflysdI\nujWVPyjp5GZf42CMHAmvfCVs3lx2JGZmg1dmN9p1wD0R8Vrg9cAjwKXAqog4FbgvvUbSDOAiYAYw\nG7heUj2r3gDMj4hOoFPS7FQ+H+hL5dcC1zTnsoaOBwmYWasoJdlIOhZ4W0QsAoiIPRGxAzgPWJwO\nWwycn7bnAMsiYndErAceA2ZKmgyMi4jV6bgluXPydd0OnFPgJRXCgwTMrFWU1bKZDjwp6SZJ35X0\nRUlHAZMiYks6ZgswKW1PAXpy5/cAU/sp703lpOcNkCUzYIekCYVcTUE8SMDMWsWoEt/3dOAjEfGQ\npC+QuszqIiIkNeWb+4ULF+7brtVq1Gq1ZrztIbkbzcyqoLu7m+7u7kHVUVay6QF6IuKh9Po24DJg\ns6QTImJz6iLbmvb3AtNy55+Y6uhN243l9XNOAjZKGgUcGxFP9RdMPtlUydSpcP/9ZUdhZu2u8UN4\nV1fXYddRSjdaRGwGNkg6NRW9E/gR8M/AvFQ2D7gzbd8NzJU0WtJ0oBNYnerZmUayCbgYuCt3Tr2u\nC8gGHAwr7kYzs1ZRVssG4KPAlySNBv4DeD8wElguaT6wHrgQICLWSloOrAX2AAtyk2MWADcDHWSj\n21ak8huBpZLWAX3A3GZc1FDyYpxm1io8qbOikzoBtm2DU06BHTvKjsTMbL9hNanTDm38eHj++WwV\nATOz4czJpsIkz7Uxs9bgZFNxHiRgZq3AyabiPNfGzFqBk03FuRvNzFqBk03FuWVjZq3Ayabi3LIx\ns1ZQ5qROewkGM0AgIhs6/cwz+x/PPps979qV7R9KFZ2u1DQ6rFkHza+vKMMlznY1ciS89a1lR+Fk\nU3lTpsBPfgJXXXVgshjo0bh/1CgYOza76+fYsfsfY8bAiALate36h6ddE/dwibOddXTAihWHPq5o\nXkGgwisIAOzZA3/+59kvdT1RNCaOgco7OrJkY2Y2lF7OCgJONhVPNmZmVePlaszMrJKcbMzMrHBO\nNmZmVjgnGzMzK5yTjZmZFc7JxszMCudkY2ZmhXOyMTOzwjnZmJlZ4ZxszMyscE42ZmZWuFKTjaSR\nkr4n6Z/T6wmSVkl6VNJKSeNzx14maZ2kRyTNypWfIWlN2nddrnyMpFtT+YOSTm7u1ZmZWV3ZLZuP\nA2uB+kqYlwKrIuJU4L70GkkzgIuAGcBs4Hpp32L2NwDzI6IT6JQ0O5XPB/pS+bXANU24nkJ0d3eX\nHcJL4jiHluMcWo6zXKUlG0knAr8B/CNQTxznAYvT9mLg/LQ9B1gWEbsjYj3wGDBT0mRgXESsTsct\nyZ2Tr+t24JyCLqVww+U/n+McWo5zaDnOcpXZsrkW+DSwN1c2KSK2pO0twKS0PQXoyR3XA0ztp7w3\nlZOeNwBExB5gh6QJQ3kBZmb20pSSbCT9JrA1Ir7H/lbNAdJNZnyjGTOzVhARTX8AnyVrdfwU2AQ8\nDSwFHgFOSMdMBh5J25cCl+bOXwHMBE4Afpwrfx9wQ+6Ys9L2KODJAWIJP/zwww8/Du9xuH/3S79T\np6SzgU9FxLsl/SXZl/rXSLoUGB8Rl6YBArcAZ5J1j30NeE1EhKRvAR8DVgNfBf4mIlZIWgC8LiI+\nLGkucH5EzC3jGs3M2l1V7lBfz3hXA8slzQfWAxcCRMRaScvJRq7tARbk7uW8ALgZ6ADuiYgVqfxG\nYKmkdUAf4ERjZlaS0ls2ZmbW+sqeZ1MaSbPTBNF1kj5Tdjz9kTRN0tcl/UjSDyV9rOyYDqZxkm4V\nSRov6TZJP5a0VtJZZcfUKE1g/lGarHyLpDFlxwQgaZGkLZLW5MoGnIhdlgHi/Fz6N39Y0h2Sji0z\nxhTTi+LM7fukpL1VGEE7UJySPpp+pj+UdMh5jG2ZbCSNBP6ObILoDOB9kl5bblT92g18IiJ+BTgL\n+MOKxlnXOEm3iq4j6259LfB64Mclx3MASacAHwROj4jXASOpThfwTWS/M3n9TsQuWX9xrgR+JSLe\nADwKXNb0qF6svziRNA04F3i86RH170VxSvp1srmMr4+IXwU+f6hK2jLZkA00eCwi1kfEbuDLZBNH\nKyUiNkfE99P2L8j+ME4pN6r+DTBJt1LSp9m3RcQigIjYExE7Sg6r0U6yDxljJY0CxpLNHytdRDwA\nbGsoHmgidmn6izMiVkVEfU7ft4ATmx5YgwF+ngB/DfxJk8MZ0ABxfhj4i/T3k4h48lD1tGuy2Tfh\nM6lPEq2s9In3NLJflCrqb5Ju1UwHnpR0k6TvSvqipLFlB5UXEU8BfwU8AWwEtkfE18qN6qAGmohd\nZR8A7ik7iP5ImgP0RMQPyo7lEDqBt6d1J7slvfFQJ7RrsqlyN8+LSDoauA34eGrhVMpLmaRbEaOA\n04HrI+J0svldVej22UfSq4E/Ak4ha8UeLel3Sw3qJRoOE7El/SnwfETcUnYsjdIHn8uBK/PFJYVz\nKKOA4yLiLLIPmcsPdUK7JpteYFru9TQOXPamMiQdQba22z9FxJ1lxzOA/wKcJ+mnwDLgHZKWlBxT\nf3rIPjU+lF7fRpZ8quSNwDcjoi8ts3QH2c+3qrZIOgEgrVW4teR4BiTp98m6equavF9N9iHj4fS7\ndCLwHUm20ufXAAADrElEQVSvLDWq/vWQ/d8k/T7tlTTxYCe0a7L5NtkK0adIGk22ovTdJcf0Imll\n6xuBtRHxhbLjGUhEXB4R0yJiOtmX2fdHxCVlx9UoIjYDGySdmoreCfyoxJD68whwlqSO9O//TrJB\nF1V1NzAvbc8DKvmBKK0G/2lgTkTsKjue/kTEmoiYFBHT0+9SD9lAkSom8DuBdwCk36fREdF3sBPa\nMtmkT4wfAe4l+0W+NSIqNSopeQvwe8CvpyHF38vdQqHKqtyV8lHgS5IeJhuN9tmS4zlARDxMtnr5\nt4F6v/0/lBfRfpKWAd8EfknSBknvJ5uIfa6kR8n++FxdZozQb5wfAP4WOBpYlX6Pri81SA6I89Tc\nzzOvEr9HA8S5CHhVGg69DDjkh0tP6jQzs8K1ZcvGzMyay8nGzMwK52RjZmaFc7IxM7PCOdmYmVnh\nnGzMzKxwTjZmgyDpF+n5ZEnvG+K6L294/W9DWb9ZMznZmA1OfaLadOB3DufEtKrzwRywDH5EvOVw\n6jerEicbs6FxNfC2NDv945JGpBt2rU437PoQgKSapAck3QX8MJXdKenb6SZUH0xlVwMdqb6lqaze\nilKqe42kH0i6MFd3t6SvpJta/VM9OElXK7sh28OSPtfUn4wZ2cqdZjZ4nwE+FRHvBkjJZXtEnKns\nTpv/KmllOvY0sht51W+O9f6I2CapA1gt6baIuFTSH0bEabn3qLeifgt4A9lyO68AHpL0jbTv18hu\nCLgJ+DdJbyFbb+38iPjlFNsxBVy/2UG5ZWM2NBqXgp8FXCLpe8CDwATgNWnf6lyiAfi4pO8D/062\nAnnnId7rrcAtkdkK/D/gTWTJaHVEbEzL/X8fOBnYDuySdKOk9wDPvuyrNHuZnGzMivORiDgtPV6d\nuwna0/UDJNWAc4CzIuLXgO8BRx6i3uDFya3e6nkuV/YCcEREvEB2d9rbgN8EVrycizEbDCcbs6Hx\nc2Bc7vW9wIL6IABJpw5wV9BjgG0RsUvSLwNn5fbtHmAQwQPARel7oVcAbwdWM8CNtiQdBYyPiH8B\n/pisC86sqfydjdng1FsUDwMvpO6wm4C/IbsR1nfTfWm2Au9Jx+eXWl8B/IGktcBPyLrS6v4B+IGk\n70TExfXzIuL/SHpzes8APh0RWyW9lhcvSx9kSfAuSUeSJaRPDMmVmx0G32LAzMwK5240MzMrnJON\nmZkVzsnGzMwK52RjZmaFc7IxM7PCOdmYmVnhnGzMzKxwTjZmZla4/w+fiqCrrBJLRwAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10af914d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEPCAYAAABiCi5wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1107b7b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAEPCAYAAABm//5NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFCGwAYoQ2ABFCGyAIgQ2QBECG6CI/wfCHY0a51LTggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cb21f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR AT ITERATION 3\n",
      "(('Non-inveratable sigma_w', array([[  5.43956479e-12,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [  0.00000000e+00,   1.15086397e-12,   0.00000000e+00,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [  0.00000000e+00,   0.00000000e+00,   4.76631861e-12,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          2.15501488e-11,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00,   5.11042211e-11,   0.00000000e+00,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00,   0.00000000e+00,   1.62613668e-12,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          1.39711110e-12,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00,   1.13241414e-12,   0.00000000e+00,\n",
      "          0.00000000e+00],\n",
      "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00,   0.00000000e+00,   1.12991612e-12,\n",
      "          0.00000000e+00],\n",
      "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "          1.09681502e-12]]), array([ 0.93273598]), array([[[ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        ..., \n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077]],\n",
      "\n",
      "       [[ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        ..., \n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077]],\n",
      "\n",
      "       [[ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        ..., \n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077]],\n",
      "\n",
      "       ..., \n",
      "       [[ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        ..., \n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077]],\n",
      "\n",
      "       [[ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        ..., \n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077]],\n",
      "\n",
      "       [[ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        ..., \n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077],\n",
      "        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n",
      "          0.09987077,  0.09987077]]]), 998.70772681301651),)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "('Non-inveratable sigma_w', array([[  5.43956479e-12,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00],\n       [  0.00000000e+00,   1.15086397e-12,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00],\n       [  0.00000000e+00,   0.00000000e+00,   4.76631861e-12,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00],\n       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          2.15501488e-11,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00],\n       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   5.11042211e-11,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00],\n       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   1.62613668e-12,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00],\n       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          1.39711110e-12,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00],\n       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   1.13241414e-12,   0.00000000e+00,\n          0.00000000e+00],\n       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   1.12991612e-12,\n          0.00000000e+00],\n       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          1.09681502e-12]]), array([ 0.93273598]), array([[[ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        ..., \n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077]],\n\n       [[ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        ..., \n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077]],\n\n       [[ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        ..., \n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077]],\n\n       ..., \n       [[ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        ..., \n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077]],\n\n       [[ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        ..., \n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077]],\n\n       [[ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        ..., \n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077]]]), 998.70772681301651)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-704-b16438ece31d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"Hinton plot of $\\langle \\mathbf{W} \\rangle $\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mloss_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mloss_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#plt.yscale('log')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-703-1b708f32ac5d>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, max_iter, convergence_rate, debug)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__update_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__update_tau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-703-1b708f32ac5d>\u001b[0m in \u001b[0;36m__sanity_check\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    195\u001b[0m                     ('Non-inveratable sigma_z', self.E_tau, self.E_W_inner))\n\u001b[1;32m    196\u001b[0m         debug_assert(invertable(np.diag(self.E_alpha[:,0]) + self.E_tau*self.E_zn_outer.sum() ),\n\u001b[0;32m--> 197\u001b[0;31m                      ('Non-inveratable sigma_w', np.diag(self.E_alpha[:,0]),self.E_tau,self.E_zn_outer,self.E_zn_outer.sum()))\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-703-1b708f32ac5d>\u001b[0m in \u001b[0;36mdebug_assert\u001b[0;34m(assertion, *printargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ERROR AT ITERATION %i'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprintargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0massertion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprintargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mdebug_assert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_alpha\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b_alpha > 0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ('Non-inveratable sigma_w', array([[  5.43956479e-12,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00],\n       [  0.00000000e+00,   1.15086397e-12,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00],\n       [  0.00000000e+00,   0.00000000e+00,   4.76631861e-12,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00],\n       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          2.15501488e-11,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00],\n       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   5.11042211e-11,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00],\n       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   1.62613668e-12,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00],\n       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          1.39711110e-12,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00],\n       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   1.13241414e-12,   0.00000000e+00,\n          0.00000000e+00],\n       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   1.12991612e-12,\n          0.00000000e+00],\n       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n          1.09681502e-12]]), array([ 0.93273598]), array([[[ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        ..., \n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077]],\n\n       [[ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        ..., \n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077]],\n\n       [[ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        ..., \n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077]],\n\n       ..., \n       [[ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        ..., \n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077]],\n\n       [[ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        ..., \n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077]],\n\n       [[ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        ..., \n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077],\n        [ 0.09987077,  0.09987077,  0.09987077, ...,  0.09987077,\n          0.09987077,  0.09987077]]]), 998.70772681301651)"
     ]
    }
   ],
   "source": [
    "#generate tha bishop data\n",
    "N = 100\n",
    "d=10\n",
    "#cov = np.tile([5,4,3,2]+[1]*(d-4),(d,1))\n",
    "cov = np.diag([5,4,3,2]+[1]*(d-4))\n",
    "mean = [0]*d\n",
    "print('mean:', mean)\n",
    "print('cov:', cov)\n",
    "X = np.random.multivariate_normal(mean, cov, N).T\n",
    "\n",
    "for q in [1,None]:\n",
    "    PCA = BayesianPCA(*X.shape, q=q)\n",
    "    hinton(PCA.means_w.T)\n",
    "    plt.title(r\"Hinton plot of $\\langle \\mathbf{W} \\rangle $\")\n",
    "    plt.show()\n",
    "    loss_log = PCA.fit(X, debug=True)\n",
    "    plt.plot(-loss_log)\n",
    "    #plt.yscale('log')\n",
    "    plt.title('convergence')\n",
    "    plt.ylabel('-$\\mathcal{L}$')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.show()\n",
    "\n",
    "    hinton(PCA.means_w.T)\n",
    "    plt.title(r\"Hinton plot of $\\langle \\mathbf{W} \\rangle $\")\n",
    "    #print( PCA.means_w)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. PCA Representation of MNIST (10 points)\n",
    "\n",
    "Download the MNIST dataset from here http://deeplearning.net/tutorial/gettingstarted.html (the page contains python code for loading the data). Run your algorithm on (part of) this dataset, and visualize the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEZCAYAAACAZ8KHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJw4zMyuLE4eZmZXFicPMzMry/+g0pvAdkLuKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11060ed90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEPCAYAAACukxSbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cc50b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if sys.version_info < (3,):\n",
    "    try:\n",
    "        import cPickle as pickle\n",
    "    except:\n",
    "        import pickle\n",
    "    import gzip\n",
    "    # Load the dataset\n",
    "    f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "    train_set, valid_set, test_set = pickle.load(f)\n",
    "    f.close()\n",
    "else:\n",
    "    import _pickle as pickle\n",
    "    import gzip\n",
    "    f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "    train_set, valid_set, test_set = pickle.load(f,encoding='latin1')\n",
    "    f.close()\n",
    "\n",
    "X = train_set[0][:100,:]\n",
    "PCA = BayesianPCA(*X.shape, q=40)\n",
    "loss_log = PCA.fit(X,max_iter=2)\n",
    "\n",
    "plt.plot(-loss_log)\n",
    "plt.title('convergence')\n",
    "plt.ylabel('-$\\mathcal{L}$')\n",
    "plt.xlabel('Iterations')\n",
    "plt.show()\n",
    "\n",
    "hinton(PCA.means_w)\n",
    "plt.title(r\"Hinton plot of $\\langle \\mathbf{W} \\rangle $\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> The hinton plot shows the each $\\mw$ as a column. We can see some kind of selection along the d-axis, instead of the q-axis. This indicates that we perhaps swaped dimensions somewhere.\n",
    "\n",
    "> However, we worked out the expressions in the code very carefully, we wrote all our code using a $q < d$ to prevent dimension errors. For the expectations of which the result was a scalar, we did a double check of the intermediate results.\n",
    "\n",
    "> We also wrote all sums as matrix operations in our code. We are aware of the fact that this may be prone to mistakes. However, we checked all computations nummerically by implementing them as a for loop and comparing the results. Therefore we are confident that the matrix expressions wil evaluate to what we intended them to.\n",
    "\n",
    "> We wrote some routines for debugging, but unfortunately we do not have any more time to find our mistake(s). \n",
    "\n",
    "> Also, it is quite complicated to debug an algorithm like this. We did quite a few tedious derivations, where we could have made a mathematical mistake. Implementing these complex expressions may also have introduced an error.\n",
    "\n",
    "\n",
    "> Even tough we did implemented a loss function for sanity checking, deriving this loss function was almost more difficult than deriving the update equations.\n",
    "\n",
    "> Would we have more time, we would have started by carfully evaluating our expectations. A good starting point for this may be numerical approximation using an integral. (Though this can quickly become infeasable due to the curse of dimensionality). However, using small values for $p$ and $q$ this will reveal most errors (both mathematical and implementational).\n",
    "\n",
    "> Once we have corrected our expectations the algorithm should work fine. If not, we can investigate our update expressions by again replacing complex matrix operations with simple for loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
